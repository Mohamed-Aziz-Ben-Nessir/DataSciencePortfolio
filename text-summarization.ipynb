{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**in this notebook i will be performing both abstractive and extractive text summarization on an arabic corpus using respectively fine tuned bert and T5 models for arabic from the pretrained huggingface transformers collection**","metadata":{}},{"cell_type":"code","source":"pip install transformers bert-extractive-summarizer ","metadata":{"execution":{"iopub.status.busy":"2021-10-06T17:00:01.925831Z","iopub.execute_input":"2021-10-06T17:00:01.926186Z","iopub.status.idle":"2021-10-06T17:00:08.459769Z","shell.execute_reply.started":"2021-10-06T17:00:01.926156Z","shell.execute_reply":"2021-10-06T17:00:08.457942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModel, AutoConfig , AutoModelForSeq2SeqLM\nfrom summarizer import Summarizer","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-06T17:00:08.461902Z","iopub.execute_input":"2021-10-06T17:00:08.462169Z","iopub.status.idle":"2021-10-06T17:00:08.46934Z","shell.execute_reply.started":"2021-10-06T17:00:08.462139Z","shell.execute_reply":"2021-10-06T17:00:08.467883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#https://r12a.github.io/scripts/tutorial/summaries/arabic\ncorpus=\" عندما يريد العالم أن ‪يتكلّم  ، فهو يتحدّث بلغة يونيكود. تسجّل الآن لحضور المؤتمر الدولي العاشر ليونيكود ، الذي سيعقد في 10-12 آذار 1997 بمدينة مَايِنْتْس، ألمانيا. و سيجمع المؤتمر بين خبراء من كافة قطاعات الصناعة على الشبكة العالمية انترنيت ويونيكود، حيث ستتم، على الصعيدين الدولي والمحلي على حد سواء مناقشة سبل استخدام يونكود في النظم القائمة وفيما يخص التطبيقات الحاسوبية، الخطوط، تصميم النصوص والحوسبة متعددة اللغات.\"","metadata":{"execution":{"iopub.status.busy":"2021-10-06T17:00:08.471586Z","iopub.execute_input":"2021-10-06T17:00:08.471893Z","iopub.status.idle":"2021-10-06T17:00:08.487372Z","shell.execute_reply.started":"2021-10-06T17:00:08.471865Z","shell.execute_reply":"2021-10-06T17:00:08.486221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **extractive summarization**","metadata":{}},{"cell_type":"markdown","source":"**I am using the following pretrained BERT language models for Arabic :**\n\n@inproceedings{safaya-etal-2020-kuisail,\n     title = \"{KUISAIL} at {S}em{E}val-2020 Task 12: {BERT}-{CNN} for Offensive\n     Speech Identification in Social Media\",\n     author = \"Safaya, Ali  and Abdullatif, Moutasem  and Yuret, Deniz\",\n     booktitle = \"Proceedings of the Fourteenth Workshop on Semantic Evaluation\",\n     month = dec,\n     year = \"2020\",address = \"Barcelona (online)\",\n     publisher = \"International Committee for Computational Linguistics\",\n     url = \"https://www.aclweb.org/anthology/2020.semeval-1.271\",\n     pages = \"2054--2059\",\n }","metadata":{}},{"cell_type":"code","source":"# Load model, model config and tokenizer via Transformers\ncustom_config = AutoConfig.from_pretrained(\"asafaya/bert-base-arabic\")\ncustom_config.output_hidden_states=True\ncustom_tokenizer = AutoTokenizer.from_pretrained(\"asafaya/bert-base-arabic\")\ncustom_model = AutoModel.from_pretrained(\"asafaya/bert-base-arabic\", config=custom_config)","metadata":{"execution":{"iopub.status.busy":"2021-10-06T17:00:08.490873Z","iopub.execute_input":"2021-10-06T17:00:08.491157Z","iopub.status.idle":"2021-10-06T17:00:15.624332Z","shell.execute_reply.started":"2021-10-06T17:00:08.491129Z","shell.execute_reply":"2021-10-06T17:00:15.622921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1= Summarizer(custom_model=custom_model, custom_tokenizer=custom_tokenizer)","metadata":{"execution":{"iopub.status.busy":"2021-10-06T17:00:15.626164Z","iopub.execute_input":"2021-10-06T17:00:15.627082Z","iopub.status.idle":"2021-10-06T17:00:15.664351Z","shell.execute_reply.started":"2021-10-06T17:00:15.62705Z","shell.execute_reply":"2021-10-06T17:00:15.663462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corpus = model1(corpus)","metadata":{"execution":{"iopub.status.busy":"2021-10-06T17:00:15.665759Z","iopub.execute_input":"2021-10-06T17:00:15.666055Z","iopub.status.idle":"2021-10-06T17:00:16.379666Z","shell.execute_reply.started":"2021-10-06T17:00:15.666026Z","shell.execute_reply":"2021-10-06T17:00:16.379098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corpus","metadata":{"execution":{"iopub.status.busy":"2021-10-06T17:00:16.380946Z","iopub.execute_input":"2021-10-06T17:00:16.381328Z","iopub.status.idle":"2021-10-06T17:00:16.388452Z","shell.execute_reply.started":"2021-10-06T17:00:16.3813Z","shell.execute_reply":"2021-10-06T17:00:16.387842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **abstractive text summarization**","metadata":{}},{"cell_type":"markdown","source":"using a test-to-test model","metadata":{}},{"cell_type":"code","source":"#https://huggingface.co/bakrianoo/t5-arabic-large\n# model2 = AutoModelForSeq2SeqLM.from_pretrained('bakrianoo/t5-arabic-large')\n# tokenizer = AutoTokenizer.from_pretrained('bakrianoo/t5-arabic-large')\n#https://github.com/google-research/multilingual-t5\n#model2 = AutoModelForSeq2SeqLM.from_pretrained(\"google/mt5-small\")\n#tokenizer = AutoTokenizer.from_pretrained(\"google/mt5-small\")\nmodel2 = model = AutoModelForSeq2SeqLM.from_pretrained(\"flax-community/arabic-t5-small\", dropout_rate=0.1)\ntokenizer=  AutoTokenizer.from_pretrained(\"flax-community/arabic-t5-small\")","metadata":{"execution":{"iopub.status.busy":"2021-10-06T17:00:16.389907Z","iopub.execute_input":"2021-10-06T17:00:16.390414Z","iopub.status.idle":"2021-10-06T17:00:24.611929Z","shell.execute_reply.started":"2021-10-06T17:00:16.390376Z","shell.execute_reply":"2021-10-06T17:00:24.610544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokens_input = tokenizer.encode(corpus,\n                             max_length=150,\n                             truncation=True,\n                             return_tensors='pt')","metadata":{"execution":{"iopub.status.busy":"2021-10-06T17:00:24.614191Z","iopub.execute_input":"2021-10-06T17:00:24.614404Z","iopub.status.idle":"2021-10-06T17:00:24.62326Z","shell.execute_reply.started":"2021-10-06T17:00:24.614382Z","shell.execute_reply":"2021-10-06T17:00:24.621988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"summary_ids = model2.generate(tokens_input)","metadata":{"execution":{"iopub.status.busy":"2021-10-06T17:00:24.626418Z","iopub.execute_input":"2021-10-06T17:00:24.626693Z","iopub.status.idle":"2021-10-06T17:00:25.496862Z","shell.execute_reply.started":"2021-10-06T17:00:24.62667Z","shell.execute_reply":"2021-10-06T17:00:25.496017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corpus = tokenizer.decode(summary_ids[0], skip_special_tokens=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-06T17:00:25.498251Z","iopub.execute_input":"2021-10-06T17:00:25.498414Z","iopub.status.idle":"2021-10-06T17:00:25.503318Z","shell.execute_reply.started":"2021-10-06T17:00:25.498394Z","shell.execute_reply":"2021-10-06T17:00:25.502677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corpus","metadata":{"execution":{"iopub.status.busy":"2021-10-06T17:00:25.504647Z","iopub.execute_input":"2021-10-06T17:00:25.505033Z","iopub.status.idle":"2021-10-06T17:00:25.522646Z","shell.execute_reply.started":"2021-10-06T17:00:25.505Z","shell.execute_reply":"2021-10-06T17:00:25.521757Z"},"trusted":true},"execution_count":null,"outputs":[]}]}